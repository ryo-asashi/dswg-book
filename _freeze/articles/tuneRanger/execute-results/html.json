{
  "hash": "d40d33423a69f2c02868b32953722ecf",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"tuneRanger\"\nauthor: \"データサイエンス関連基礎調査WG\"\ndate: \"2025-08-01\"\nformat:\n  html:\n    toc: true\n    toc-depth: 3\n    fig-width: 6\n    fig-height: 3\n---\n\n\n\n\n\n\n## パッケージの概要\n\n機械学習におけるRandomForestモデルの構築を行えます。また、tuneRangerではハイパーパラメータのチューニングを行う機能も提供されます。\n\n## 参考URL\n\n公式ドキュメント <https://cran.r-project.org/web/packages/tuneRanger/tuneRanger.pdf>\n\nRの機械学習パッケージmlrのチュートリアル（タスクの作成から予測まで） <https://qiita.com/nozma/items/bedcb35cba925764247a>\n\n## 使用例：irisデータの分類\n\nirisデータを用いて、がく弁・花弁の長さ・幅の情報からアヤメの種類を特定するRandomForestモデルをtuneRangerパッケージを用いて構築します。\n\n### irisデータセットを読み込む\nirisデータを読み込み、データの先頭を表示します。\n\n-   Sepal.Length：がく弁の長さ\n-   Sepal.Width：がく弁の幅\n-   Petal.Length：花弁の長さ\n-   Petal.Width：花弁の幅\n\nアヤメの種類はsetosa(1)、versicolor(2)、virginica(3)の3種類です\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata(iris)\nhead(iris)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n1          5.1         3.5          1.4         0.2  setosa\n2          4.9         3.0          1.4         0.2  setosa\n3          4.7         3.2          1.3         0.2  setosa\n4          4.6         3.1          1.5         0.2  setosa\n5          5.0         3.6          1.4         0.2  setosa\n6          5.4         3.9          1.7         0.4  setosa\n```\n\n\n:::\n:::\n\n\n\n### irisデータの構造\n\nirisデータの各種構造を確認します。\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstr(iris)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n'data.frame':\t150 obs. of  5 variables:\n $ Sepal.Length: num  5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ...\n $ Sepal.Width : num  3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ...\n $ Petal.Length: num  1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ...\n $ Petal.Width : num  0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ...\n $ Species     : Factor w/ 3 levels \"setosa\",\"versicolor\",..: 1 1 1 1 1 1 1 1 1 1 ...\n```\n\n\n:::\n:::\n\n\n\n\nまた、データを散布図にプロットして確認します。\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(iris, col=c(2, 3, 4)[iris$Species])\n```\n\n::: {.cell-output-display}\n![](tuneRanger_files/figure-html/unnamed-chunk-3-1.png){width=576}\n:::\n:::\n\n\n\n\n### データセットの準備\n\nirisデータをモデル生成のための訓練データと、モデル評価のためのテストデータに分割します。データ割合は訓練データを7割、テストデータを3割とします\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# 再現性のためにシードを設定\nset.seed(100)\n\n# データの分割\nn <- nrow(iris)\ntrain.rate <- 0.7\n\n# データそのものではなく、データ番号を吐き出している\n(train.set <- sample(n, n * train.rate))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  [1] 102 112   4  55  70  98 135   7  43 140  51  25   2  68 137  48  32  85\n [19]  91 121  16 116  66 146  93  45  30 124 126  87  95  97 120  29  92  31\n [37]  54  41 105 113  24 142 143  63  65   9 150  20  14  78  88   3  36  27\n [55]  46  59  96  69  47 147 129 136  12 141 130  56  22  82  53  99   5  44\n [73]  28  52 139  42  15  57  75  37  26 110 100 149 132 107  35  58 127 111\n [91] 144  86 114  71 123 119  18   8 128  83 138  19 115  23  89\n```\n\n\n:::\n\n```{.r .cell-code}\n(test.set <- setdiff(1:n, train.set))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1]   1   6  10  11  13  17  21  33  34  38  39  40  49  50  60  61  62  64  67\n[20]  72  73  74  76  77  79  80  81  84  90  94 101 103 104 106 108 109 117 118\n[39] 122 125 131 133 134 145 148\n```\n\n\n:::\n:::\n\n\n\n\n### モデル生成\nmakeClassifTaskにてタスクの定義を行い、makeLeanerにて適用するアルゴリズムの選択を行います。\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n(task <- makeClassifTask(data = iris, target = \"Species\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nSupervised task: iris\nType: classif\nTarget: Species\nObservations: 150\nFeatures:\n   numerics     factors     ordered functionals \n          4           0           0           0 \nMissings: FALSE\nHas weights: FALSE\nHas blocking: FALSE\nHas coordinates: FALSE\nClasses: 3\n    setosa versicolor  virginica \n        50         50         50 \nPositive class: NA\n```\n\n\n:::\n\n```{.r .cell-code}\nlrn <- makeLearner(\"classif.lda\")\n```\n:::\n\n\n\n分割したデータセットを基にモデルの訓練を行います。また、訓練時の誤分類率(mmce)や精度(ace)を把握することが出来ます。\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n(model <- train(lrn, task, subset = train.set))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nModel for learner.id=classif.lda; learner.class=classif.lda\nTrained on: task.id = iris; obs = 105; features = 4\nHyperparameters: \n```\n\n\n:::\n:::\n\n\n\n\n### パラメータチューニング\n\nパラメータチューニングのための実行時間を事前に知ることが出来ます。\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nestimateTimeTuneRanger(task, num.trees = 500, num.threads = 3, iters = 30)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nApproximated time for tuning: 50S\n```\n\n\n:::\n:::\n\n\n\n\ntuneRangerを使用して、実際にパラメータチューニングをやってみます。\n\n\n\n::: {.cell}\n\n:::\n\n\n\n\nチューニング後のモデルの精度を確認してみます。精度が向上していることが分かります。\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npred.res <- predict(res$model, task = task, subset = test.set)\nperformance(pred.res, measures = list(mmce, acc))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      mmce        acc \n0.02222222 0.97777778 \n```\n\n\n:::\n:::\n",
    "supporting": [
      "tuneRanger_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}