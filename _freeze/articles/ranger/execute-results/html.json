{
  "hash": "19e4cd54e3b6e9e6f5dbded3dae60b17",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"ranger\"\nauthor: \"データサイエンス関連基礎調査WG\"\ndate: \"2025-08-01\"\nformat:   \n  html:\n    toc: true\n    toc-depth: 3\n    fig-width: 6\n    fig-height: 3\n---\n\n\n\n\n\n\n## パッケージの概要\n\n機械学習におけるRandomForestモデルを構築できます。高速実装であり、特に高次元データに適しています。 分類木、回帰木、生存木、確率予測木のアンサンブルをサポートしています。\n\n## 使用例：irisデータの分類\n\nirisデータを用いて、がく弁・花弁の長さ・幅の情報からアヤメの種類を特定するRandomForestモデルをrangerパッケージを用いて構築します。\n\n### irisデータセットを読み込む\n\nirisデータを読み込み、データの先頭を表示します。\n\n-   Sepal.Length：がく弁の長さ\n-   Sepal.Width：がく弁の幅\n-   Petal.Length：花弁の長さ\n-   Petal.Width：花弁の幅\n\nアヤメの種類はsetosa(1)、versicolor(2)、virginica(3)の3種類です。\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata(iris)\nhead(iris)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n1          5.1         3.5          1.4         0.2  setosa\n2          4.9         3.0          1.4         0.2  setosa\n3          4.7         3.2          1.3         0.2  setosa\n4          4.6         3.1          1.5         0.2  setosa\n5          5.0         3.6          1.4         0.2  setosa\n6          5.4         3.9          1.7         0.4  setosa\n```\n\n\n:::\n:::\n\n\n\n\n### irisデータの構造\n\nirisデータの各種構造を確認します。\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstr(iris)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n'data.frame':\t150 obs. of  5 variables:\n $ Sepal.Length: num  5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ...\n $ Sepal.Width : num  3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ...\n $ Petal.Length: num  1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ...\n $ Petal.Width : num  0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ...\n $ Species     : Factor w/ 3 levels \"setosa\",\"versicolor\",..: 1 1 1 1 1 1 1 1 1 1 ...\n```\n\n\n:::\n:::\n\n\n\n\nまた、データを散布図にプロットして確認します。\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(iris, col=c(2, 3, 4)[iris$Species])\n```\n\n::: {.cell-output-display}\n![](ranger_files/figure-html/unnamed-chunk-3-1.png){width=576}\n:::\n:::\n\n\n\n\n## モデル構築１（全体データ）\n\nまずは全てのデータを使ってRandomForestモデルを構築してみます。\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ranger)\n\n# シードを設定\nset.seed(123)\n(model.all <- ranger(Species ~ ., data = iris, importance = \"impurity\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRanger result\n\nCall:\n ranger(Species ~ ., data = iris, importance = \"impurity\") \n\nType:                             Classification \nNumber of trees:                  500 \nSample size:                      150 \nNumber of independent variables:  4 \nMtry:                             2 \nTarget node size:                 1 \nVariable importance mode:         impurity \nSplitrule:                        gini \nOOB prediction error:             5.33 % \n```\n\n\n:::\n:::\n\n\n\n\n分類木の構築においては、importance = \"impurity\"と設定することにより、結果にvariable.importanceを保持してくれます。この中身を確認することにより各変数の重要度を確認することが出来ます。irisデータの分類には花弁の長さ（Petal.Length）・花弁の幅（Petal.Width）の情報が重要であることが分かります。\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel.all$variable.importance\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nSepal.Length  Sepal.Width Petal.Length  Petal.Width \n    9.629622     2.453766    41.714390    45.460729 \n```\n\n\n:::\n:::\n\n\n\n\n### データセットの準備\n\nirisデータをモデル生成のための訓練データと、モデル評価のためのテストデータに分割します。データ割合は訓練データを7割、テストデータを3割とします。確認のため、データサイズを出力します。\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# 再現性のためにシードを設定\nset.seed(123)  \n\n# データの分割\nsample_indices <- sample(1:nrow(iris), 0.7 * nrow(iris))  \ntrain_data <- iris[sample_indices, ]\ntest_data <- iris[-sample_indices, ]\n\n# データサイズの確認\nc(nrow(iris), nrow(train_data), nrow(test_data))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 150 105  45\n```\n\n\n:::\n:::\n\n\n\n\n### モデルの生成・予測の実行\n\n訓練データを用いて分類木のモデルを生成します。モデルの生成結果は以下の通りです。\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(123)  \n(model <- ranger(Species ~ ., data = train_data))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRanger result\n\nCall:\n ranger(Species ~ ., data = train_data) \n\nType:                             Classification \nNumber of trees:                  500 \nSample size:                      105 \nNumber of independent variables:  4 \nMtry:                             2 \nTarget node size:                 1 \nVariable importance mode:         none \nSplitrule:                        gini \nOOB prediction error:             5.71 % \n```\n\n\n:::\n:::\n\n\n\n\nテストデータを用いてモデルの評価をします。まずは、テストデータを先ほど構築した分類木モデルに適用させ、その予測結果をpredictionsに格納します。\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npredictions <- predict(model, data = test_data)$predictions\n```\n:::\n\n\n\n\n予測結果とテストデータのもともとのアヤメの分類とを比較します。おおむね正しく分類できていることが分かります。\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n(confusion_matrix <- table(predictions, test_data$Species))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n            \npredictions  setosa versicolor virginica\n  setosa         14          0         0\n  versicolor      0         17         0\n  virginica       0          1        13\n```\n\n\n:::\n:::\n\n\n\n\n## ハイパーパラメーターのチューニング\n\nrangerのRandomForestモデルにおける主なハイパーパラメーターは以下の通りです。\n\n-   決定木を生成する際に使用するパラメータの数(mtry)\n-   生成する決定木の数(num.trees)\n\nこれらのハイパーパラメーターの最適な設定を探す作業がハイパーパラメーターのチューニングとなります。rangerのハイパーパラメーターのチューニング用にはtuneRanger等のパッケージがありますが、ここではnum.treesについて直接パラメータ設定を変更して精度比較を実施します。\n\nなお、rangerのRandomForestモデルではOOBError(Out-Of-bag Error)が算出されます。これはモデル構築時に一部データを学習に使用しない代わりにモデル検証に使用して誤差率を求めています。そのため、クロスバリデーションをしなくても、ある程度の汎化性能を測ることができます。\n\nnum.trees = 300としてモデル構築します。OOBErrorは5.71%です。\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(123)  \n(model.num.trees.300 <- ranger(Species ~ ., data = train_data, num.trees = 300))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRanger result\n\nCall:\n ranger(Species ~ ., data = train_data, num.trees = 300) \n\nType:                             Classification \nNumber of trees:                  300 \nSample size:                      105 \nNumber of independent variables:  4 \nMtry:                             2 \nTarget node size:                 1 \nVariable importance mode:         none \nSplitrule:                        gini \nOOB prediction error:             5.71 % \n```\n\n\n:::\n:::\n\n\n\n\nnum.trees = 500としてモデル構築します。OOBErrorは5.71%です。\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(123)  \n(model.num.trees.500 <- ranger(Species ~ ., data = train_data, num.trees = 500))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRanger result\n\nCall:\n ranger(Species ~ ., data = train_data, num.trees = 500) \n\nType:                             Classification \nNumber of trees:                  500 \nSample size:                      105 \nNumber of independent variables:  4 \nMtry:                             2 \nTarget node size:                 1 \nVariable importance mode:         none \nSplitrule:                        gini \nOOB prediction error:             5.71 % \n```\n\n\n:::\n:::\n\n\n\n\nnum.trees = 700としてモデル構築します。OOBErrorは4.76%です。\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(123)  \n(model.num.trees.700 <- ranger(Species ~ ., data = train_data, num.trees = 700))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRanger result\n\nCall:\n ranger(Species ~ ., data = train_data, num.trees = 700) \n\nType:                             Classification \nNumber of trees:                  700 \nSample size:                      105 \nNumber of independent variables:  4 \nMtry:                             2 \nTarget node size:                 1 \nVariable importance mode:         none \nSplitrule:                        gini \nOOB prediction error:             4.76 % \n```\n\n\n:::\n:::\n\n\n\n\nnum.trees = 700のときにOOBErrorが最も小さくなったので、そのモデルにてテストデータで精度を測ってみます。もともと精度が高いため、結果は変わりませんでした。\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npredictions.num.trees <- predict(model.num.trees.700, data = test_data)$predictions\n(confusion_matrix <- table(predictions.num.trees, test_data$Species))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                     \npredictions.num.trees setosa versicolor virginica\n           setosa         14          0         0\n           versicolor      0         17         0\n           virginica       0          1        13\n```\n\n\n:::\n:::\n",
    "supporting": [
      "ranger_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}